{
  "comments": [
    {
      "key": {
        "uuid": "9a5c5d37_7309de2b",
        "filename": "ci/merge.sh",
        "patchSetId": 2
      },
      "lineNbr": 16,
      "author": {
        "id": 2034
      },
      "writtenOn": "2015-11-24T04:19:54Z",
      "side": 1,
      "message": "If the python-nose-cov package is not installed, nothing will happen here.  Still need to update the JJB to report code coverage reports at some point.",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_3313665e",
        "filename": "ci/verify.sh",
        "patchSetId": 2
      },
      "lineNbr": 13,
      "author": {
        "id": 2034
      },
      "writtenOn": "2015-11-24T04:19:54Z",
      "side": 1,
      "message": "This way if flake8 is not installed on the build server, no harm done, we will pass this step.",
      "range": {
        "startLine": 13,
        "startChar": 16,
        "endLine": 13,
        "endChar": 17
      },
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_53037a73",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 58,
      "author": {
        "id": 830
      },
      "writtenOn": "2015-11-24T17:02:46Z",
      "side": 1,
      "message": "Minor nit for clarity: it looks like the message content could be made a little more clear. E.g.: \"Avg Latency (us) Read/Write: \" + read_latency + \"/\" + write_latency + \" IOPS Read/Write: \" + read_iops + \"/\" + write_iops\n\nCan we make the value captured in ms instead of us? The lowest (non-RAM disk) value I would expect to see is in the hundreds of us, whereas the highest value will be in the 10\u0027s of ms.",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_333fe627",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 58,
      "author": {
        "id": 2034
      },
      "writtenOn": "2015-11-24T20:48:37Z",
      "side": 1,
      "message": "Yes, I need to clean this up a little.",
      "parentUuid": "9a5c5d37_53037a73",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_33f8067c",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 72,
      "author": {
        "id": 830
      },
      "writtenOn": "2015-11-24T17:02:46Z",
      "side": 1,
      "message": "Just verifying behavior: if no workloads are specified in command line, then you will run all of the workloads in the workload_dir? If so, nice. I like the ease in adding new workloads.",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_533a5a37",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 72,
      "author": {
        "id": 2034
      },
      "writtenOn": "2015-11-24T20:48:37Z",
      "side": 1,
      "message": "Correct - this is the implementation of default being \u0027all\u0027.",
      "parentUuid": "9a5c5d37_33f8067c",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_17d16057",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 89,
      "author": {
        "id": 2823
      },
      "writtenOn": "2015-12-09T15:17:30Z",
      "side": 1,
      "message": "Should consider adding a phase for \"data dependent preconditioning\".  This is a phase whereby some initial data pattern is generated and executed to the block devices exposed to the client.  Typically this is different than device preconditioning (SSD preconditioning above).  One example is for compression/dedup storage targets, to have the desired data reduction or space utilization as an initial condition.",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_13f50283",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 126,
      "author": {
        "id": 830
      },
      "writtenOn": "2015-11-24T17:02:46Z",
      "side": 1,
      "message": "We may need to reverse the order of these for loops. I think you want to expand the number of streams of the workload before changing to the next workload. Ordinarily, it would not matter, but for SSD, I understand major context switching of workloads does impact its behavior. See SNIA Performance WP. This can be left as TBD for now.",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_133ce22e",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 126,
      "author": {
        "id": 2034
      },
      "writtenOn": "2015-11-24T20:48:37Z",
      "side": 1,
      "message": "Fair enough.  The question I also have is: do we redo the SSD preconditioning before the next workload?",
      "parentUuid": "9a5c5d37_13f50283",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "9a5c5d37_0eacb9ec",
        "filename": "storperf/test_executor.py",
        "patchSetId": 2
      },
      "lineNbr": 126,
      "author": {
        "id": 830
      },
      "writtenOn": "2015-11-25T13:50:50Z",
      "side": 1,
      "message": "Good question. If you look at the SNIA test spec, it calls out workload independent preconditioning first, before any testing; then, workload-dependent preconditioning per-workload test. IIRC, the workload-dependent test is simply a run of that same workload until steady state is achieved. That implies a monitoring loop that detects when steady state has been reached. I was a little skeptical about whether that would be necessary in for our use case. It is certainly worth experimenting with, but we could add that later as an experiment just as easily.",
      "parentUuid": "9a5c5d37_133ce22e",
      "revId": "002920e29d7fa4a28abec96773b470c90bafe55d",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    }
  ]
}